{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "161eafa3-b8fd-4a1d-b1f1-15b432aee95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7259fb0-4fa4-4fd4-b64f-99cfe302c4a5",
   "metadata": {},
   "source": [
    "# 자연어 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d05c8-21e6-4e85-82a9-e8125764a58e",
   "metadata": {},
   "source": [
    "### nltk 라이브러리 \n",
    "- pip install nltk\n",
    "- https://www.nltk.org/api/nltk.tokenize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3850c0f8-d15c-4c1d-bc8a-7fb39358dc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\khkim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk 테스트\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72e6f7ef-5fbf-4db2-b25b-45eca31303f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']\n"
     ]
    }
   ],
   "source": [
    "s = '''Good muffins cost $3.88\\nin New York.  Please buy me two of them.\\n\\nThanks.'''\n",
    "print(word_tokenize(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b104f90-4a7b-42c5-b7df-dfa294a3269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good', 'muffins', 'cost', '$', '3', '.', '88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "print(wordpunct_tokenize(s) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bcccafc-5b0a-464c-b6b6-86755f8fab42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 4), (5, 12), (13, 17), (18, 23), (24, 26), (27, 30), (31, 36), (38, 44), (45, 48), (49, 51), (52, 55), (56, 58), (59, 64), (66, 73)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "print(list(WhitespaceTokenizer().span_tokenize(s)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb31a89-792a-42b9-9571-9da8b46954f2",
   "metadata": {},
   "source": [
    "## 한글 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69c23a0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀(曾孫女)딸이라는 걸 알 수\n",
      "있었다. 소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다. 서울서는 이런\n",
      "개울물을 보지 못하기나 한 듯이.\n",
      "벌써 며칠째 소녀는, 학교에서 돌아오는 길에 물장난이었다. 그런데, 어제까지 개울\n",
      "기슭에서 하더니, 오늘은 징검다리 한가운데 앉아서 하고 있다.\n",
      "소년은 개울둑에 앉아\n"
     ]
    }
   ],
   "source": [
    "with open('ml_datas/소나기.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0d76c-2d38-47fa-97ba-e86162b36646",
   "metadata": {},
   "source": [
    "## 특수기호 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2854388b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀딸이라는 걸 알 수있었다. 소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다. 서울서는 이런개울물을 보지 못하기나 한 듯이.벌써 며칠째 소녀는 학교에서 돌아오는 길에 물장난이었다. 그런데 어제까지 개울기슭에서 하더니 오늘은 징검다리 한가운데 앉아서 하고 있다.소년은 개울둑에 앉아 버렸다. 소녀가 비키기\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "compile = re.compile(\"[^ ㄱ-ㅣ가-힣\\.]+\")\n",
    "text = compile.sub('', text)\n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6855d834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀딸이라는 걸 알 수있었다.', '소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다.', '서울서는 이런개울물을 보지 못하기나 한 듯이.벌써 며칠째 소녀는 학교에서 돌아오는 길에 물장난이었다.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# sent_tokenize(text, language='english')\n",
    "sentences = sent_tokenize(text)\n",
    "print(sentences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e7bb6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀딸이라는 걸 알 수있었다',\n",
       " ' 소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다',\n",
       " ' 서울서는 이런개울물을 보지 못하기나 한 듯이',\n",
       " '벌써 며칠째 소녀는 학교에서 돌아오는 길에 물장난이었다',\n",
       " ' 그런데 어제까지 개울기슭에서 하더니 오늘은 징검다리 한가운데 앉아서 하고 있다',\n",
       " '소년은 개울둑에 앉아 버렸다',\n",
       " ' 소녀가 비키기를 기다리자는 것이다',\n",
       " '요행 지나가는 사람이 있어 소녀가 길을 비켜 주었다',\n",
       " '다음 날은 좀 늦게 개울가로 나왔다',\n",
       " '이 날은 소녀가 징검다리 한가운데 앉아 세수를 하고 있었다']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split('.')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f8ccb5-9bb3-4b6e-9194-ba907070383d",
   "metadata": {},
   "source": [
    "### konlpy 라이브러리\n",
    "- JDK 설치, JAVA_HOME 설정\n",
    "- pip install --upgrade pip\n",
    "- pip install JPype1-1.4.0-cp39-cp39-win_amd64.whl\n",
    "- pip install konlpy\n",
    "- 설치 참고 : https://konlpy.org/ko/latest/install/#id2\n",
    "- 사용 방법 참고 : https://konlpy.org/ko/v0.6.0/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "078b3cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\playgrd\\ml_venv\\lib\\site-packages\\konlpy\\tag\\_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['소년', '은', '개울가에서', '소녀', '를', '보자', '곧', '윤', '초시', '네', '증손녀', '딸', '이라는', '걸', '알', '수', '있었다', '.'], ['소녀', '는', '개울', '에다', '손', '을', '잠그고', '물장난', '을', '하고', '있는', '것', '이다', '.']]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "words = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    word = twitter.morphs(sentence)\n",
    "    words.append(word)\n",
    "print(words[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71c27f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '정말', '로', '파이썬', '을', '좋', '아', '하', 'ㄴ다', '.']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "hannanum = Hannanum()\n",
    "\n",
    "test_text = '나는 정말로 파이썬을 좋아한다.'\n",
    "\n",
    "word = hannanum.morphs(test_text)\n",
    "\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5e02626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '정말로', '파이', '썰', 'ㄴ', '프로그래밍', '을', '좋아하', 'ㄴ다', '.']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "\n",
    "test_text = '나는 정말로 파이썬 프로그래밍을 좋아한다.'\n",
    "\n",
    "word = kkma.morphs(test_text)\n",
    "\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a91f58f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '정말로', '파이썬', '프로그래밍', '을', '좋아하', 'ㄴ다', '.']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran()\n",
    "\n",
    "test_text = '나는 정말로 파이썬 프로그래밍을 좋아한다.'\n",
    "\n",
    "word = komoran.morphs(test_text)\n",
    "\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b59ff449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '정말로', '파이썬', '프로그래밍', '을', '좋아하다', '.']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "test_text = '나는 정말로 파이썬 프로그래밍을 좋아한다.'\n",
    "\n",
    "word = okt.morphs(test_text, stem=True)\n",
    "\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d49fc84-01b2-4544-9816-0ca49b3a3bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '정말로', '파이썬', '프로그래밍', '을', '좋아하다', '.']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "test_text = '나는 정말로 파이썬 프로그래밍을 좋아한다.'\n",
    "\n",
    "word = okt.morphs(test_text, stem=True)\n",
    "\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e382a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['소년', '은', '개다', '소녀', '를', '보다', '곧', '윤', '초시', '네', '증손녀', '딸', '이라는', '걸', '알', '수', '있다', '.', '소녀', '는']\n"
     ]
    }
   ],
   "source": [
    "twitter = Twitter()\n",
    "\n",
    "def tw_tokenizer(text):\n",
    "    tokens_ko = twitter.morphs(text, stem=True)\n",
    "    return tokens_ko\n",
    "\n",
    "word_tokens = tw_tokenizer(text)\n",
    "print(word_tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b2f5a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['않다', '되어다', '되다', '하다', '어떻다', '이렇다', '이다', '어제', '매일', '아']\n"
     ]
    }
   ],
   "source": [
    "with open('ml_datas/stopword.txt', 'r', encoding='utf-8') as f:\n",
    "    word = f.read()\n",
    "stopwords = word.split('\\n')\n",
    "print(stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0ed77b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['소년', '은', '개다', '소녀', '보다', '윤', '초시', '증손녀', '딸', '이라는', '걸', '알', '수', '.', '소녀', '는', '개울', '에다', '손', '잠그다']\n"
     ]
    }
   ],
   "source": [
    "filter_words = []\n",
    "for word in word_tokens:\n",
    "    if word not in stopwords:\n",
    "        filter_words.append(word)\n",
    "print(filter_words[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d8947-ea9d-4f1e-b227-3304cc90f9fe",
   "metadata": {},
   "source": [
    "## TF-IDF feature 벡터화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68189035-6c2c-416d-bf42-ae8cd56a8770",
   "metadata": {},
   "source": [
    "### RfidBectorizer 객체 전달 인자\n",
    "- min_df=2: 단어가 나타나는 최소 문서 빈도를 2로 설정, 즉, 최소한 2개 이상의 문서에 등장 하는 단어만을 고려함\n",
    "- tokenizer = ok_tokenizer: 사용자 정의 토크 나이저인 ok_tokenizer 지정함 텍스트를 단어 단위로 분할하는 역할을 수행\n",
    "- stop_words = stopwords: 불용어 목록인 stopwords를 지정하여 텍스트에서 제거할 단어들을 설정함\n",
    "- ngram_range=(1, 2): 단어의 n-gram 범위를 1부터 2로 설정함. 단어의 단일 토큰과 2개의 연속된 단어로 구성된 토큰을 모두 고려한다는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2e1668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 58)\t1\n",
      "  (0, 574)\t1\n",
      "  (0, 675)\t1\n",
      "  (0, 680)\t1\n",
      "  (0, 722)\t1\n",
      "  (0, 1045)\t1\n",
      "  (0, 1093)\t1\n",
      "  (1, 62)\t1\n",
      "  (1, 96)\t1\n",
      "  (1, 512)\t1\n",
      "  (1, 670)\t1\n",
      "  (1, 703)\t1\n",
      "  (1, 955)\t1\n",
      "  (1, 984)\t1\n",
      "  (1, 1124)\t1\n",
      "  (2, 171)\t1\n",
      "  (2, 346)\t1\n",
      "  (2, 388)\t1\n",
      "  (2, 471)\t1\n",
      "  (2, 489)\t1\n",
      "  (2, 513)\t1\n",
      "  (2, 551)\t1\n",
      "  (2, 578)\t1\n",
      "  (2, 658)\t1\n",
      "  (2, 670)\t1\n",
      "  :\t:\n",
      "  (174, 105)\t1\n",
      "  (174, 147)\t1\n",
      "  (174, 198)\t1\n",
      "  (174, 308)\t1\n",
      "  (174, 664)\t1\n",
      "  (174, 780)\t1\n",
      "  (174, 816)\t1\n",
      "  (174, 851)\t1\n",
      "  (174, 920)\t1\n",
      "  (174, 1048)\t1\n",
      "  (174, 1094)\t1\n",
      "  (175, 165)\t1\n",
      "  (175, 185)\t1\n",
      "  (175, 293)\t1\n",
      "  (175, 433)\t1\n",
      "  (175, 502)\t1\n",
      "  (175, 780)\t1\n",
      "  (175, 884)\t1\n",
      "  (175, 912)\t1\n",
      "  (175, 953)\t1\n",
      "  (175, 971)\t1\n",
      "  (175, 972)\t1\n",
      "  (175, 1037)\t1\n",
      "  (175, 1038)\t1\n",
      "  (175, 1165)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# cnt_vect = CountVectorizer(tokenizer = tw_tokenizer, \n",
    "#                            stop_words = stopwords)\n",
    "# cnt_vect = CountVectorizer(stop_words = stopwords)\n",
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(sentences)\n",
    "words_cnt_vect = cnt_vect.transform(sentences)\n",
    "print(words_cnt_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ffff740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_cnt_vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbf6a8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<177x845 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2050 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer = tw_tokenizer, \n",
    "                           stop_words = stopwords)\n",
    "tfidf_vect.fit(sentences)\n",
    "words_tfidf_vect = tfidf_vect.transform(sentences)\n",
    "words_tfidf_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b77f703-4653-4977-9116-406110880396",
   "metadata": {},
   "source": [
    "## 국민 청원 수집 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e4041c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answered</th>\n",
       "      <th>votes</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>2017-11-17</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>안전/환경</td>\n",
       "      <td>스텔라 데이지호에 대한 제안입니다.</td>\n",
       "      <td>스텔라 데이지호에 대한 제안입니다.\\n3월31일 스텔라 데이지호가 침몰하고 5달째가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>2017-11-17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>기타</td>\n",
       "      <td>비리제보처를 만들어주세요.</td>\n",
       "      <td>현 정부에 국민들이 가장 원하는 것은 부패척결입니다.  우리 사회에 각종 비리들이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>2017-09-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>미래</td>\n",
       "      <td>제2의 개성공단</td>\n",
       "      <td>만일 하시는 대통령님 및 각 부처 장관님,주무관님들 안녕하세요!!\\n전남 목포에서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>2017-08-26</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>일자리</td>\n",
       "      <td>공공기관 무조건적인 정규직전환을 반대합니다.</td>\n",
       "      <td>현정부에서 정규직 일자리를 늘리는 것에 찬성합니다. 그런데 공공기관 비정규직들은 인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>2017-09-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>미래</td>\n",
       "      <td>제2의 개성공단</td>\n",
       "      <td>만일 하시는 대통령님 및 각 부처 장관님,주무관님들 안녕하세요!!\\n전남 목포에서 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id       start         end  answered  votes category  \\\n",
       "0          21  2017-08-19  2017-11-17         0      9    안전/환경   \n",
       "1          22  2017-08-19  2017-11-17         0     17       기타   \n",
       "2          23  2017-08-19  2017-09-03         0      0       미래   \n",
       "3          24  2017-08-19  2017-08-26         0     53      일자리   \n",
       "4          25  2017-08-19  2017-09-03         0      0       미래   \n",
       "\n",
       "                      title                                            content  \n",
       "0       스텔라 데이지호에 대한 제안입니다.  스텔라 데이지호에 대한 제안입니다.\\n3월31일 스텔라 데이지호가 침몰하고 5달째가...  \n",
       "1            비리제보처를 만들어주세요.  현 정부에 국민들이 가장 원하는 것은 부패척결입니다.  우리 사회에 각종 비리들이 ...  \n",
       "2                  제2의 개성공단  만일 하시는 대통령님 및 각 부처 장관님,주무관님들 안녕하세요!!\\n전남 목포에서 ...  \n",
       "3  공공기관 무조건적인 정규직전환을 반대합니다.  현정부에서 정규직 일자리를 늘리는 것에 찬성합니다. 그런데 공공기관 비정규직들은 인...  \n",
       "4                  제2의 개성공단  만일 하시는 대통령님 및 각 부처 장관님,주무관님들 안녕하세요!!\\n전남 목포에서 ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('ml_datas/petition.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b9aeca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 395547 entries, 0 to 395546\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   article_id  395547 non-null  int64 \n",
      " 1   start       395547 non-null  object\n",
      " 2   end         395547 non-null  object\n",
      " 3   answered    395547 non-null  int64 \n",
      " 4   votes       395547 non-null  int64 \n",
      " 5   category    395547 non-null  object\n",
      " 6   title       395547 non-null  object\n",
      " 7   content     395546 non-null  object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 24.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b18308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3955 entries, 356947 to 5539\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   article_id  3955 non-null   int64 \n",
      " 1   start       3955 non-null   object\n",
      " 2   end         3955 non-null   object\n",
      " 3   answered    3955 non-null   int64 \n",
      " 4   votes       3955 non-null   int64 \n",
      " 5   category    3955 non-null   object\n",
      " 6   title       3955 non-null   object\n",
      " 7   content     3955 non-null   object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 278.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=0.01, random_state=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a709d613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['정치개혁', '외교/통일/국방', '경제민주화', '기타', '육아/교육', '안전/환경', '보건복지', '일자리',\n",
       "       '인권/성평등', '문화/예술/체육/언론', '성장동력', '교통/건축/국토', '미래', '행정', '반려동물',\n",
       "       '저출산/고령화대책', '농산어촌'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3425feb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356947</th>\n",
       "      <td>언제까지 국회의원들의 무능에 한탄만 하고 있겠습니까?\\n국민의 뜻이라 변명하는 국회...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284969</th>\n",
       "      <td>군면제 대상들의 서류를 미성년자도 아닌데 형제,남매꺼 까지 통장내역서 월급내역서 등...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389760</th>\n",
       "      <td>국민연금으로 국유화( 대한항공)즉 주식개입(국민연금)으로 국가입맛에 맞는 기업정관을...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388934</th>\n",
       "      <td>저는 산재사고로 장애6급판정을 받았습니다.\\n상완신경총 손상으로 오른쪽팔중 어깨,팔...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27900</th>\n",
       "      <td>조두순 출소 반대 합니다.\\n무기징역으로...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content  category\n",
       "356947  언제까지 국회의원들의 무능에 한탄만 하고 있겠습니까?\\n국민의 뜻이라 변명하는 국회...        15\n",
       "284969  군면제 대상들의 서류를 미성년자도 아닌데 형제,남매꺼 까지 통장내역서 월급내역서 등...        10\n",
       "389760  국민연금으로 국유화( 대한항공)즉 주식개입(국민연금)으로 국가입맛에 맞는 기업정관을...         0\n",
       "388934  저는 산재사고로 장애6급판정을 받았습니다.\\n상완신경총 손상으로 오른쪽팔중 어깨,팔...         2\n",
       "27900                           조두순 출소 반대 합니다.\\n무기징역으로...        11"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_data = df.loc[:, ['content', 'category']]\n",
    "\n",
    "lb_enc = LabelEncoder()\n",
    "df_data['category'] = lb_enc.fit_transform(df_data.loc[:, 'category'])\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26872862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleaner(text):\n",
    "    compile = re.compile('[^ ㄱ-ㅣ가-힣]+')\n",
    "    text = compile.sub('', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4828e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['content'] = df_data.loc[:, 'content'].apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "889d9828",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['content'] = df_data.loc[:, 'content'].apply(lambda x: compile.sub('', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "440a401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3164 791\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data['content'], \n",
    "                                                    df_data['category'], \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe0520e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cnt_vect = CountVectorizer(tokenizer=tw_tokenizer,\n",
    "                           stop_words = stopwords)\n",
    "cnt_vect.fit(X_train)\n",
    "X_train_cnt_vect = cnt_vect.transform(X_train)\n",
    "X_test_cnt_vect = cnt_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a57d8429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer = tw_tokenizer,\n",
    "                           stop_words = stopwords)\n",
    "\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0709520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countvecterizer 정확도 : 0.4197218710493047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators= 200)\n",
    "rf_clf.fit(X_train_cnt_vect, y_train)\n",
    "pred = rf_clf.predict(X_test_cnt_vect)\n",
    "print('Countvecterizer 정확도 :',accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5e7a203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer 정확도 : 0.42098609355246525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators= 200, random_state = 0)\n",
    "rf_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = rf_clf.predict(X_test_tfidf_vect)\n",
    "print('TfidfVectorizer 정확도 :',accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb7324e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "review_df = pd.read_csv('ml_datas/labeledTrainData.tsv', header = 0, sep='\\t', quoting = 3)\n",
    "\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d480c280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>The Classic War of the Worlds by Timothy Hines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager Nicholas Bell g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  With all this stuff going down at the moment w...\n",
       "1  \"2381_9\"          1  The Classic War of the Worlds by Timothy Hines...\n",
       "2  \"7759_3\"          0  The film starts with a manager Nicholas Bell g...\n",
       "3  \"3630_4\"          0  It must be assumed that those who praised this...\n",
       "4  \"9495_8\"          1  Superbly trashy and wondrously unpretentious s..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['review'] = review_df['review'].str.replace('<br />','')\n",
    "review_df['review'] = review_df['review'].apply(lambda x : re.sub('[^ a-zA-Z]','',x))\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e4532ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_df = review_df['sentiment']\n",
    "feature_df = review_df['review']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(feature_df, class_df, test_size=0.3, random_state=156)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35e15606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('cnt_vect', CountVectorizer(stop_words = 'english', ngram_range=(1,2))),\n",
    "    ('lr_clf', LogisticRegression(solver = 'liblinear', C = 10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48ab6dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8848 0.884744906669702\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "pred = pipeline.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, pred), roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad22f028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\khkim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\sentiwordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2dd8b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return \n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "def swn_polarity(text):\n",
    "    sentiment = 0.0\n",
    "    tokens_count = 0\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    raw_sentences = sent_tokenize(text)\n",
    "    for raw_sentence in raw_sentences:\n",
    "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
    "        for word , tag in tagged_sentence:\n",
    "            \n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            if wn_tag not in (wn.NOUN , wn.ADJ, wn.ADV):\n",
    "                continue                   \n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            if not lemma:\n",
    "                continue\n",
    "            synsets = wn.synsets(lemma , pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    "            synset = synsets[0]\n",
    "            swn_synset = swn.senti_synset(synset.name())\n",
    "            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())           \n",
    "            tokens_count += 1\n",
    "    \n",
    "    if not tokens_count:\n",
    "        return 0\n",
    "\n",
    "    if sentiment >= 0 :\n",
    "        return 1\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea5bf6a-2ba7-49cb-8195-901e29537a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_ex",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
